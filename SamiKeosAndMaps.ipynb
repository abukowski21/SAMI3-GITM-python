{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b210e-9331-4c32-963e-b7f64cbcaa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d6fc58c-4346-46fe-9e0c-4fde89655d30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# All SAMI3 field line plots and Data Analysis used in the Sim Storm Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b40e0f-72b9-4484-93cf-0e96b274ac23",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34badf75-77a8-4175-808a-5b38230fda68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import aacgmv2, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import math, os, shutil\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import readsav\n",
    "import pymap3d as pm\n",
    "import glob\n",
    "import datetime, statistics\n",
    "from aetherpy.io import read_routines\n",
    "from math import cos, radians, sin, sqrt\n",
    "from scipy import spatial, signal\n",
    "\n",
    "from spacepy.coordinates import Coords\n",
    "from spacepy.time import Ticktock\n",
    "import fnmatch\n",
    "\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas\n",
    "\n",
    "from scipy.interpolate import LinearNDInterpolator, interp1d, griddata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bba9c3-9b64-48bd-a30e-ee22cf82ec55",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b857631-26df-4069-99c8-c24481070f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime_storm_start = datetime.datetime(2011,5,21,13,40) \n",
    "\n",
    "dtime_sim_start = datetime.datetime(2011,5,20)\n",
    "\n",
    "t_step_minutes = 5 # minutes\n",
    "\n",
    "\n",
    "plot_start_delta  = 4  # hours before storm onset to start making plots. set to -1 to run the whole time\n",
    "plot_end_delta    = -1  # hours after storm onset to end plots. Set to -1 to run for the whole time\n",
    "\n",
    "sami_data_path = \"/home/axb170054/scratch/GITM-testing/test_folders/step_function_driving/SAMI3-stretch/\"\n",
    "\n",
    "lon_keos = [-90,2,90,-178]\n",
    "\n",
    "global_lat_lim = None # will limit all plots latitude. Must be none or less than keo_lat_lim\n",
    "# ^^ Needs to be tested.\n",
    "\n",
    "keo_lat_lim = 65 # limits keos to +/- degrees of lat. \n",
    "\n",
    "OVERWRITE = True # be careful!\n",
    "\n",
    "# num_pool_workers = int(0.75 * os.cpu_count()) # number of workers to use in multithreading jobs. Set to 1 if you don't know what this means. \n",
    "num_pool_workers = 6\n",
    "\n",
    "sample_rate_min = 5 #min\n",
    "low_cut = 100 # min, lowest freq wave the filter will allow thru\n",
    "high_cut = 30 # min, highest freq the filter will allow thru\n",
    "\n",
    "glons_to_plot = 10 #number of field lines you want to plot. Not necessary. You can set to none if you want to plot stuff yourself\n",
    "alts_to_plot = 10 # Number of altitudes to make maps & keos of.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b601a761-cd18-4585-acd2-25e530f62c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sami_keo_save_path = \"/home/axb170054/scratch/made_plots/SimStormPaper/SAMI/keos/\"\n",
    "sami_map_save_path = \"/home/axb170054/scratch/made_plots/SimStormPaper/SAMI/maps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16acb88e-5668-448d-ae94-d57b713e0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']\n",
    "\n",
    "# above is all cols (that I care about), below is just edens.\n",
    "\n",
    "#cols = ['edens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b44408-6354-4ebb-bc8f-9e3511d41984",
   "metadata": {},
   "source": [
    "Available columns (for now) are:\n",
    "\n",
    "['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1098c-aad1-4f11-b828-eae03bc3f929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7f38d96-4a01-4bc8-a96d-0d743dfbf4ef",
   "metadata": {},
   "source": [
    "## Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4427ba-bf48-4968-86f5-ed7e92cb44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_grid_files = {'glat':'glatu.dat','glon':'glonu.dat','alt':'zaltu.dat', \n",
    "                  'mlat':'blatu.dat','mlon':'blonu.dat','malt':'baltu.dat'}\n",
    "\n",
    "\n",
    "data_files = {'edens':'deneu.dat', 'hplusdens':'deni1u.dat','oplusdens':'deni2u.dat',\n",
    "              'noplusdens':'deni3u.dat', 'o2plusdens':'deni4u.dat',\n",
    "              'heplusdens':'deni5u.dat', 'n2plusdens':'deni6u.dat', \n",
    "              'nplusdens':'deni7u.dat','hdens':'denn1u.dat','odens':'denn2u.dat', \n",
    "              'nodens':'denn3u.dat', 'o2dens':'denn4u.dat', 'hedens':'denn5u.dat', \n",
    "              'n2dens':'denn6u.dat', 'ndens':'denn7u.dat'}\n",
    "\n",
    "time_file = 'time.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c298b60-b693-4748-b327-afb068e7b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a685a146-4128-4b1b-966f-5571bf318db5",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49149adb-0212-4602-9e63-ce6001235801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grid_elems_from_parammod(data_dir):\n",
    "    \"\"\"\n",
    "    Will look for: words = ['nz0','nf','nl'] in SAMI files.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    sami path\n",
    "    \n",
    "    outputs:\n",
    "    -------\n",
    "    nz,nf,nlt,nt :\n",
    "    - nz  = num points along field line\n",
    "    - nf  = num field lines along each mag lon\n",
    "    - nlt = num mag lons\n",
    "    - nt  = num times\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Make sure that we only grab the first instance of each var in the file. \n",
    "        # SOmetimes they repeat and we don't want them\n",
    "    returns = [False, False, [False, False], False]\n",
    "    \n",
    "    with open(data_dir  + 'parameter_mod.f90', 'r') as fp:\n",
    "    # read all lines in a list\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            # check if string present on a current line\n",
    "            \n",
    "            if not returns[0]:\n",
    "                if line.find('nz0') != -1:\n",
    "                    nz0 = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nz0.append(l)\n",
    "                    if len(nz0[1:4]) == 3:\n",
    "                        nz = int(''.join(nz0[1:4]))\n",
    "                        returns[0] = True\n",
    "            \n",
    "            if not returns[1]:\n",
    "                if line.find('nf') != -1:\n",
    "                    nf = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nf.append(l)\n",
    "                    nf = int(''.join(nf))\n",
    "                    returns[1] = True\n",
    "                    \n",
    "            if not returns[2][0]:\n",
    "                if line.find('nl ') != -1:\n",
    "                    nl = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nl.append(l)\n",
    "                    nl = int(''.join(nl))\n",
    "                    returns[2][0] = True\n",
    "                    \n",
    "            if not returns[2][1]:\n",
    "                if line.find('numwork ') != -1:\n",
    "                    numwork = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            numwork.append(l)\n",
    "                    numwork = int(''.join(numwork))\n",
    "                    returns[2][1] = True\n",
    "                    \n",
    "    #time\n",
    "    with open(data_dir  + 'time.dat', 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        nt = len(lines) - 1\n",
    "            \n",
    "    return nz, nf, numwork*(nl - 2), nt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac07d09a-8fa4-4f93-a2f9-161c4b440c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_times(t0, nt, plot_start_delta = None, plot_end_delta = None):\n",
    "    times = []\n",
    "    hrs_since_storm_start = []\n",
    "    \n",
    "    for t in range(nt):\n",
    "        time_here = pd.Timestamp(dtime_sim_start) + t * pd.Timedelta(5, 'minutes')\n",
    "        times.append(time_here.to_pydatetime())\n",
    "        hrs = (time_here - dtime_storm_start)/pd.Timedelta(1, 'hour')\n",
    "        hrs_since_storm_start.append(hrs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    times_df = pd.read_fwf(os.path.join(sami_data_path, 'time.dat'), \n",
    "                            names = ['istep', 'hour', 'minute', 'second', 'hrdelta'], infer_nrows=115)\n",
    "    times_df.pop('istep');\n",
    "\n",
    "    times_list = []\n",
    "    for hr in times_df['hrdelta']:\n",
    "        times_list.append(dtime_sim_start + datetime.timedelta(hours = hr))    \n",
    "    \n",
    "    truths = np.array([pd.Timestamp(times_list[t]).round('T') == times[t] for t in range(len(times))])\n",
    "    if truths.sum() != len(truths):\n",
    "        raise ValueError('The times are wrong! Somehow this needs to be fixed. probably outputting fake files again. Take a look and debug before proceeding.')\n",
    "        \n",
    "    #maybe chop the time lists, depending on if the plot start/end are given.\n",
    "    # adjusted to allow for -1 in plot start/end deltas (plot all times)\n",
    "        \n",
    "    if plot_start_delta and plot_end_delta:\n",
    "        if plot_start_delta != -1:\n",
    "            start_idx = np.argmin(np.abs(np.array(times) \n",
    "                                     - (dtime_storm_start - pd.Timedelta(plot_start_delta, 'hour'))))\n",
    "        else:\n",
    "            start_idx = 0\n",
    "            \n",
    "        if plot_end_delta != -1:\n",
    "            end_idx = plot_end_delta\n",
    "        elif plot_end_delta == -1:\n",
    "            end_idx = len(times)\n",
    "        else:\n",
    "            end_idx = len(times)\n",
    "        \n",
    "        times = times[start_idx:end_idx]\n",
    "        hrs_since_storm_start = hrs_since_storm_start[start_idx:end_idx]\n",
    "        times_list = times_list[start_idx:end_idx]\n",
    "        \n",
    "        return times, hrs_since_storm_start, times_list, (start_idx, end_idx)\n",
    "        \n",
    "    elif plot_start_delta != plot_end_delta:\n",
    "        raise ValueError('You cannot specify one and not the other!')\n",
    "    \n",
    "    return times, hrs_since_storm_start, times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffcfef34-2d49-49f1-8303-e5c44401d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UT_from_Storm_onset(itime):\n",
    "    \"\"\"input a datetime\n",
    "    \n",
    "    returns the UT as HH:MM from storm onset, as a string\"\"\"\n",
    "    l = (pd.Timestamp(itime) - dtime_storm_start)/ pd.Timedelta('1 minute') # get pd datetime of this iter, find minute diff from storm start\n",
    "    if l > 0:\n",
    "        hrs = np.floor(l/60)\n",
    "        hrs = str(int(hrs)).rjust(2,'0')\n",
    "    else:\n",
    "        hrs = np.ceil(l/60)\n",
    "        hrs = '-' + str(np.abs(int(hrs))).rjust(2,'0')\n",
    "    mins = str(int(np.abs(l)%60)).rjust(2,'0')\n",
    "    ut = hrs + ':' + mins\n",
    "    return ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a63b2b-b613-463e-8d2e-0da650fc6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sami_grid(sami_data_path = sami_data_path, geo_grid_files = geo_grid_files):\n",
    "\n",
    "    grid = {}\n",
    "\n",
    "    for f in geo_grid_files:\n",
    "        file = open(os.path.join(sami_data_path, geo_grid_files[f]), 'rb')\n",
    "        raw = np.fromfile(file, dtype='float32')[1:-1].copy()\n",
    "        file.close()\n",
    "\n",
    "        grid[f] = raw.reshape(nlt,nf,nz).copy()\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34644ef0-8ec1-453d-873e-bc3ca05b1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sami_data(cols, nts):\n",
    "    \"\"\"\n",
    "    Read in sami data for the specified columns and return sama data dict\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    cols: list-like\n",
    "        - Columns you want data for. Does not have to be everything\n",
    "    \n",
    "    nts: int OR tuple/list\n",
    "        - either nt (number of times) if you want all sami data from simulation or:\n",
    "        - nts (start_time, end_time) if you want plots from a select time period.\n",
    "    \n",
    "    \"\"\"\n",
    "    sami_data = {}\n",
    "    \n",
    "    #handle cut time list and full time list\n",
    "    if type(nts) != int:\n",
    "        t_start = nts[0]\n",
    "        t_end   = nts[1]\n",
    "        ntimes = t_end - t_start\n",
    "    else:\n",
    "        t_start = 0\n",
    "        t_end = nt\n",
    "        ntimes = nt\n",
    "        \n",
    "    pbar = tqdm(total = len(cols) * ntimes)\n",
    "\n",
    "    for f in cols:\n",
    "\n",
    "        sami_data[f] = np.zeros((nlt,nf,nz,ntimes))\n",
    "\n",
    "        file = open(os.path.join(sami_data_path, data_files[f]), 'rb')\n",
    "        for t in range(t_end):\n",
    "            raw = np.fromfile(file, dtype='float32', count = (nz*nf*nlt)+2)[1:-1]\n",
    "            if t >= t_start:\n",
    "                sami_data[f][:,:,:,t-t_start] = raw.reshape(nlt,nf,nz).copy()\n",
    "                pbar.update(1)\n",
    "        file.close()\n",
    "    pbar.close()\n",
    "        \n",
    "    return sami_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "886f5502-11f1-4606-a219-b80564b29e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(params = None):\n",
    "    # Define the cutoff frequencies\n",
    "    lowcut = 1/(100/60)  # 100 minutes in units of sample^-1\n",
    "    highcut = 1/(30/60) # 30 minutes in units of sample^-1\n",
    "\n",
    "    # Define the Butterworth filter\n",
    "    nyquist = 0.5 * 5 # 5 minutes is the sampling frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    sos = signal.butter(2, [low, high], btype='bandstop', output='sos')\n",
    "    return sos\n",
    "\n",
    "def remove_background(time_series, sos):\n",
    "\n",
    "\n",
    "    # Apply the filter to the time series\n",
    "    filtered_data = signal.sosfiltfilt(sos, time_series)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def make_fits(gitm_bins):\n",
    "    \"\"\"\n",
    "    calculate bandpass filter for all data previously read in.\n",
    "    \n",
    "    inputs: nparray of gitmdata\n",
    "    \n",
    "    returns:\n",
    "    fits: np array indexed at fits[time][col][ilon][ilat][ialt]\n",
    "\n",
    "    \n",
    "    todo: you can thread this by splitting the alts into different threads.\n",
    "    then just append the fits_full later.\n",
    "    \n",
    "    \"\"\"\n",
    "    sos = make_filter()\n",
    "    filtered_arr = {}\n",
    "    for col in cols:\n",
    "        filtered_arr[col] = signal.sosfiltfilt(sos, sami_data[col], axis=3)\n",
    "    return filtered_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9173b0d2-0f6c-479e-a1a8-073611a2b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(array):\n",
    "    arr2 = array.copy()\n",
    "    mean, std, median = np.mean(arr2), np.std(arr2), np.median(arr2) # calculate mean, standard deviation, and median over all elements\n",
    "    outlier_threshold = 5 # set outlier threshold (in terms of number of standard deviations)\n",
    "    outliers = np.logical_or(arr2 < mean - outlier_threshold * std, arr2 > mean + outlier_threshold * std) # find outliers\n",
    "    arr2[outliers] = median # set outliers to median\n",
    "    return arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154791af-680e-45eb-bb5c-efb8c462f003",
   "metadata": {},
   "source": [
    "## Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469b898-144b-4a74-b825-cf3119e13ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8214a1e-1df3-46e4-beb4-187cb78e76e5",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864ee73-67c6-440f-9758-54d0dc081b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be21cc98-5d6b-4d30-90d6-23f922de5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz, nf, nlt, nt = get_grid_elems_from_parammod(sami_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8899b9f7-5c3a-4cd5-8837-53e0f993ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "times, hrs, times_list, nts = make_times(dtime_sim_start, nt, plot_start_delta, plot_end_delta)\n",
    "new_nt = np.diff(nts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "958a4d73-49e3-4571-ac69-09cdf8c25f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OR.... to run for all times:\n",
    "# times, hrs, times_list = make_times(dtime_sim_start, nt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c7c99c-06a7-4ff3-bd41-6523dedac6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 72 256 (404, 615) 211\n"
     ]
    }
   ],
   "source": [
    "print(nlt, nf, nz, nts, new_nt)\n",
    "nt = new_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd664453-6a29-4c4b-ba52-fa8eebf6e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_sami_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6fb04c4-c746-4cc0-9549-fe3d76a219d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glat (80, 72, 256)\n",
      "glon (80, 72, 256)\n",
      "alt (80, 72, 256)\n",
      "mlat (80, 72, 256)\n",
      "mlon (80, 72, 256)\n",
      "malt (80, 72, 256)\n"
     ]
    }
   ],
   "source": [
    "for g in grid.keys():\n",
    "    print(g, grid[g].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92e039d1-81bb-4977-b283-32b295f1b774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9de1069b4d24f8d9bb9c60fda4ce62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sami data shape:  (80, 72, 256, 211)\n"
     ]
    }
   ],
   "source": [
    "# sami grid\n",
    "sami_data = read_sami_data(cols, nts)\n",
    "# or\n",
    "# sami_data = read_sami_data(cols, nt)\n",
    "\n",
    "print('sami data shape: ', sami_data[cols[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e437fcf-4830-4c3c-bc64-6795e926d46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating fits. This will take a moment...\n"
     ]
    }
   ],
   "source": [
    "print('Calculating fits. This will take a moment...')\n",
    "fits_sami = make_fits(sami_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d8aa6-bae5-4809-8046-feaaf789894d",
   "metadata": {},
   "source": [
    "## more setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93893836-43ff-4ad8-af9f-dd413d195db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlons = np.unique(grid['mlon'].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83d38c90-766e-415c-814f-65f1ec1ddaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlon_step = np.floor((len(mlons) +1) / mlons_to_plot)\n",
    "mlon_idxs = list(range(0,nlt,int(mlon_step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "860207ec-55dc-4249-838b-2f7d1e989ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will plot 10 mlons, here are the indices & the actual mlon:\n",
      "0 2.25\n",
      "8 38.25\n",
      "16 74.25\n",
      "24 110.25\n",
      "32 146.25\n",
      "40 182.25\n",
      "48 218.25\n",
      "56 254.25\n",
      "64 290.25\n",
      "72 326.25\n"
     ]
    }
   ],
   "source": [
    "print('we will plot %i mlons, here are the indices & the actual mlon:' %len(mlon_idxs))\n",
    "[print(i, mlons[i]) for i in mlon_idxs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169e081-b0e5-4806-a001-bd3c7adb54f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a6c61-eede-4b70-b41b-815c2892feef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e6370-63c9-4512-a700-564b1a191969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f6658-d3a1-46f7-964a-28eeb76a277d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cf254-a91c-45b0-ae47-84f8df4d1f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e1d24-f357-4108-b618-58237c90948a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8b78a-08fb-44bd-b73e-4d0ae580c0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
