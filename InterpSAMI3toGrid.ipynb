{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691b33d-3de4-4897-ab9d-535ad34609b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01555b18-1a55-469f-ac5c-6ea4c45a5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import aacgmv2, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import math, os, shutil\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import readsav\n",
    "import pymap3d as pm\n",
    "import glob\n",
    "import datetime, statistics\n",
    "from aetherpy.io import read_routines\n",
    "from math import cos, radians, sin, sqrt\n",
    "from scipy import spatial, signal\n",
    "\n",
    "from spacepy.coordinates import Coords\n",
    "from spacepy.time import Ticktock\n",
    "import fnmatch\n",
    "\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import geopandas\n",
    "\n",
    "from scipy.interpolate import LinearNDInterpolator, interp1d, griddata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ff191-7c04-428d-8a81-c17ab9fdfcc8",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d83e43-9a75-44f3-ad71-c83a71360efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime_storm_start = datetime.datetime(2011,5,21,13,40) \n",
    "\n",
    "dtime_sim_start = datetime.datetime(2011,5,20)\n",
    "\n",
    "t_step_minutes = 5 # minutes\n",
    "\n",
    "\n",
    "plot_start_delta  = 2  # hours before storm onset to start making plots. set to -1 to run the whole time\n",
    "plot_end_delta    = 6  # hours after storm onset to end plots. Set to -1 to run for the whole time\n",
    "\n",
    "sami_data_path = \"/home/axb170054/scratch/GITM-testing/test_folders/step_function_driving/SAMI3-stretch/\"\n",
    "\n",
    "\n",
    "global_lat_lim = 65 # will limit SAMI output data to this GEO latitude\n",
    "\n",
    "\n",
    "OVERWRITE = True # be careful!\n",
    "\n",
    "\n",
    "\n",
    "sample_rate_min = 5 # SHOULD be the same as t_step_minutes above. If not, something will be wrong. Won't throw errors. Gotta pay attention.\n",
    "low_cut = 80 # min, lowest freq wave the filter will allow thru\n",
    "high_cut = 40 # min, highest freq the filter will allow thru\n",
    "\n",
    " #Do we want to run the filtering? if not, this will need to be done later.\n",
    "to_filter = False # I'll adjust this later..\n",
    "debug = False # make plots at the end? I would leave this as False. At the bottom there are some simple plotting routines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b35c0a-5b44-4bff-8bc2-c20ad6eb1f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6040fcc7-0777-4e0a-8100-48ef32295916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']\n",
    "\n",
    "# above is all cols (that I care about), below is just edens.\n",
    "\n",
    "# cols = ['edens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804d66f-a768-49f3-a67f-82ad7d977388",
   "metadata": {},
   "source": [
    "Available columns (for now) are:\n",
    "\n",
    "['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4588e6d7-6fc5-40c3-b029-26535b368b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_path = '/home/axb170054/scratch/pickles/SimStormPaper/simstorm_sami_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a65552d-890d-42bb-9a1c-e1d52836d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thread = True\n",
    "num_workers = len(cols) # adjust this to fit your system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8962264b-72ce-43d4-b77f-47e437bb01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grid_lats = 65\n",
    "out_grid_lons = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a1d00a-952c-4604-a92d-4208cb65949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_alts = np.linspace(out_alt_min, out_alt_max, num_out_grid_alts)\n",
    "out_lats = np.linspace(-global_lat_lim,global_lat_lim, out_grid_lats)\n",
    "out_lons = np.linspace(0,360, out_grid_lons +1)[1:] # we don't need both 0 & 360. the 1's deal with that.\n",
    "out_alts = np.array([250,300,350,400,450,500,550,600,700,800,840,880,900,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6ebc12-1a21-4ca8-8225-8fc353b2ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-65.     , -62.96875, -60.9375 , -58.90625, -56.875  , -54.84375,\n",
       "        -52.8125 , -50.78125, -48.75   , -46.71875, -44.6875 , -42.65625,\n",
       "        -40.625  , -38.59375, -36.5625 , -34.53125, -32.5    , -30.46875,\n",
       "        -28.4375 , -26.40625, -24.375  , -22.34375, -20.3125 , -18.28125,\n",
       "        -16.25   , -14.21875, -12.1875 , -10.15625,  -8.125  ,  -6.09375,\n",
       "         -4.0625 ,  -2.03125,   0.     ,   2.03125,   4.0625 ,   6.09375,\n",
       "          8.125  ,  10.15625,  12.1875 ,  14.21875,  16.25   ,  18.28125,\n",
       "         20.3125 ,  22.34375,  24.375  ,  26.40625,  28.4375 ,  30.46875,\n",
       "         32.5    ,  34.53125,  36.5625 ,  38.59375,  40.625  ,  42.65625,\n",
       "         44.6875 ,  46.71875,  48.75   ,  50.78125,  52.8125 ,  54.84375,\n",
       "         56.875  ,  58.90625,  60.9375 ,  62.96875,  65.     ]),\n",
       " array([  4.8,   9.6,  14.4,  19.2,  24. ,  28.8,  33.6,  38.4,  43.2,\n",
       "         48. ,  52.8,  57.6,  62.4,  67.2,  72. ,  76.8,  81.6,  86.4,\n",
       "         91.2,  96. , 100.8, 105.6, 110.4, 115.2, 120. , 124.8, 129.6,\n",
       "        134.4, 139.2, 144. , 148.8, 153.6, 158.4, 163.2, 168. , 172.8,\n",
       "        177.6, 182.4, 187.2, 192. , 196.8, 201.6, 206.4, 211.2, 216. ,\n",
       "        220.8, 225.6, 230.4, 235.2, 240. , 244.8, 249.6, 254.4, 259.2,\n",
       "        264. , 268.8, 273.6, 278.4, 283.2, 288. , 292.8, 297.6, 302.4,\n",
       "        307.2, 312. , 316.8, 321.6, 326.4, 331.2, 336. , 340.8, 345.6,\n",
       "        350.4, 355.2, 360. ]),\n",
       " array([ 250,  300,  350,  400,  450,  500,  550,  600,  700,  800,  840,\n",
       "         880,  900, 1000]),\n",
       " 65,\n",
       " 75,\n",
       " 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lats, out_lons, out_alts, len(out_lats), len(out_lons), len(out_alts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31be945-574a-4a9f-8c4d-463ec5dfaab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bdea72-c7ec-4691-871c-5a97e4990c6c",
   "metadata": {},
   "source": [
    "## Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aef03d2-d9ff-4b97-856a-33129c0a97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_grid_files = {'glat':'glatu.dat','glon':'glonu.dat','alt':'zaltu.dat', \n",
    "                  'mlat':'blatu.dat','mlon':'blonu.dat','malt':'baltu.dat'}\n",
    "\n",
    "\n",
    "data_files = {'edens':'deneu.dat', 'hplusdens':'deni1u.dat','oplusdens':'deni2u.dat',\n",
    "              'noplusdens':'deni3u.dat', 'o2plusdens':'deni4u.dat',\n",
    "              'heplusdens':'deni5u.dat', 'n2plusdens':'deni6u.dat', \n",
    "              'nplusdens':'deni7u.dat','hdens':'denn1u.dat','odens':'denn2u.dat', \n",
    "              'nodens':'denn3u.dat', 'o2dens':'denn4u.dat', 'hedens':'denn5u.dat', \n",
    "              'n2dens':'denn6u.dat', 'ndens':'denn7u.dat'}\n",
    "\n",
    "time_file = 'time.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fe50e-3a3d-465b-9343-18e00c00150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5934c36f-340d-4676-860e-39b4a4ab8db0",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c96832d5-41e5-4bba-80b7-ea1b9d117c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grid_elems_from_parammod(data_dir):\n",
    "    \"\"\"\n",
    "    Will look for: words = ['nz0','nf','nl'] in SAMI files.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    sami path\n",
    "    \n",
    "    outputs:\n",
    "    -------\n",
    "    nz,nf,nlt,nt :\n",
    "    - nz  = num points along field line\n",
    "    - nf  = num field lines along each mag lon\n",
    "    - nlt = num mag lons\n",
    "    - nt  = num times\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Make sure that we only grab the first instance of each var in the file. \n",
    "        # SOmetimes they repeat and we don't want them\n",
    "    returns = [False, False, [False, False], False]\n",
    "    \n",
    "    with open(data_dir  + 'parameter_mod.f90', 'r') as fp:\n",
    "    # read all lines in a list\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            # check if string present on a current line\n",
    "            \n",
    "            if not returns[0]:\n",
    "                if line.find('nz0') != -1:\n",
    "                    nz0 = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nz0.append(l)\n",
    "                    if len(nz0[1:4]) == 3:\n",
    "                        nz = int(''.join(nz0[1:4]))\n",
    "                        returns[0] = True\n",
    "            \n",
    "            if not returns[1]:\n",
    "                if line.find('nf') != -1:\n",
    "                    nf = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nf.append(l)\n",
    "                    nf = int(''.join(nf))\n",
    "                    returns[1] = True\n",
    "                    \n",
    "            if not returns[2][0]:\n",
    "                if line.find('nl ') != -1:\n",
    "                    nl = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nl.append(l)\n",
    "                    nl = int(''.join(nl))\n",
    "                    returns[2][0] = True\n",
    "                    \n",
    "            if not returns[2][1]:\n",
    "                if line.find('numwork ') != -1:\n",
    "                    numwork = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            numwork.append(l)\n",
    "                    numwork = int(''.join(numwork))\n",
    "                    returns[2][1] = True\n",
    "                    \n",
    "    #time\n",
    "    with open(data_dir  + 'time.dat', 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        nt = len(lines) - 1\n",
    "            \n",
    "    return nz, nf, numwork*(nl - 2), nt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73c89024-7bd4-4e03-971b-04ed0daad573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_times(t0, nt, plot_start_delta = None, plot_end_delta = None):\n",
    "    times = []\n",
    "    hrs_since_storm_start = []\n",
    "    \n",
    "    for t in range(nt):\n",
    "        time_here = pd.Timestamp(dtime_sim_start) + t * pd.Timedelta(5, 'minutes')\n",
    "        times.append(time_here.to_pydatetime())\n",
    "        hrs = (time_here - dtime_storm_start)/pd.Timedelta(1, 'hour')\n",
    "        hrs_since_storm_start.append(hrs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    times_df = pd.read_fwf(os.path.join(sami_data_path, 'time.dat'), \n",
    "                            names = ['istep', 'hour', 'minute', 'second', 'hrdelta'], infer_nrows=115)\n",
    "    times_df.pop('istep');\n",
    "\n",
    "    times_list = []\n",
    "    for hr in times_df['hrdelta']:\n",
    "        times_list.append(dtime_sim_start + datetime.timedelta(hours = hr))    \n",
    "    \n",
    "    truths = np.array([pd.Timestamp(times_list[t]).round('T') == times[t] for t in range(len(times))])\n",
    "    if truths.sum() != len(truths):\n",
    "        raise ValueError('The times are wrong! Somehow this needs to be fixed. probably outputting fake files again. Take a look and debug before proceeding.')\n",
    "        \n",
    "    #maybe chop the time lists, depending on if the plot start/end are given.\n",
    "    # adjusted to allow for -1 in plot start/end deltas (plot all times)\n",
    "        \n",
    "    if plot_start_delta and plot_end_delta:\n",
    "        if plot_start_delta != -1:\n",
    "            start_idx = np.argmin(np.abs(np.array(times) \n",
    "                                     - (dtime_storm_start - pd.Timedelta(plot_start_delta, 'hour'))))\n",
    "        else:\n",
    "            start_idx = 0\n",
    "            \n",
    "        if plot_end_delta != -1:\n",
    "            end_idx = np.argmin(np.abs(np.array(times) \n",
    "                                     - (dtime_storm_start + pd.Timedelta(plot_end_delta, 'hour'))))\n",
    "        elif plot_end_delta == -1:\n",
    "            end_idx = len(times)\n",
    "        else:\n",
    "            end_idx = len(times)\n",
    "        \n",
    "        times = times[start_idx:end_idx]\n",
    "        hrs_since_storm_start = hrs_since_storm_start[start_idx:end_idx]\n",
    "        times_list = times_list[start_idx:end_idx]\n",
    "        \n",
    "        return times, hrs_since_storm_start, times_list, (start_idx, end_idx)\n",
    "        \n",
    "    elif plot_start_delta != plot_end_delta:\n",
    "        raise ValueError('You cannot specify one and not the other!')\n",
    "    \n",
    "    return times, hrs_since_storm_start, times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d71c30a-7aa6-45de-949f-093c2e1ecd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UT_from_Storm_onset(itime):\n",
    "    \"\"\"input a datetime\n",
    "    \n",
    "    returns the UT as HH:MM from storm onset, as a string\"\"\"\n",
    "    l = (pd.Timestamp(itime) - dtime_storm_start)/ pd.Timedelta('1 minute') # get pd datetime of this iter, find minute diff from storm start\n",
    "    if l > 0:\n",
    "        hrs = np.floor(l/60)\n",
    "        hrs = str(int(hrs)).rjust(2,'0')\n",
    "    else:\n",
    "        hrs = np.ceil(l/60)\n",
    "        hrs = '-' + str(np.abs(int(hrs))).rjust(2,'0')\n",
    "    mins = str(int(np.abs(l)%60)).rjust(2,'0')\n",
    "    ut = hrs + ':' + mins\n",
    "    return ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd9f2ee0-e5db-4ed4-9a25-2b68ad88cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sami_grid(sami_data_path = sami_data_path, geo_grid_files = geo_grid_files):\n",
    "\n",
    "    grid = {}\n",
    "\n",
    "    for f in geo_grid_files:\n",
    "        file = open(os.path.join(sami_data_path, geo_grid_files[f]), 'rb')\n",
    "        raw = np.fromfile(file, dtype='float32')[1:-1].copy()\n",
    "        file.close()\n",
    "\n",
    "        grid[f] = raw.reshape(nlt,nf,nz).copy()\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b81a498-d13a-4223-8d88-c30f078322d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sami_data(cols, nts):\n",
    "    \"\"\"\n",
    "    Read in sami data for the specified columns and return sama data dict\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    cols: list-like\n",
    "        - Columns you want data for. Does not have to be everything\n",
    "    \n",
    "    nts: int OR tuple/list\n",
    "        - either nt (number of times) if you want all sami data from simulation or:\n",
    "        - nts (start_time, end_time) if you want plots from a select time period.\n",
    "    \n",
    "    \"\"\"\n",
    "    sami_data = {}\n",
    "    \n",
    "    #handle cut time list and full time list\n",
    "    if type(nts) != int:\n",
    "        t_start = nts[0]\n",
    "        t_end   = nts[1]\n",
    "        ntimes = t_end - t_start\n",
    "    else:\n",
    "        t_start = 0\n",
    "        t_end = nt\n",
    "        ntimes = nt\n",
    "        \n",
    "    pbar = tqdm(total = len(cols) * ntimes, desc = 'reading sami data')\n",
    "\n",
    "    for f in cols:\n",
    "\n",
    "        sami_data[f] = np.zeros((nlt,nf,nz,ntimes))\n",
    "\n",
    "        file = open(os.path.join(sami_data_path, data_files[f]), 'rb')\n",
    "        for t in range(t_end):\n",
    "            raw = np.fromfile(file, dtype='float32', count = (nz*nf*nlt)+2)[1:-1]\n",
    "            if t >= t_start:\n",
    "                sami_data[f][:,:,:,t-t_start] = raw.reshape(nlt,nf,nz).copy()\n",
    "                pbar.update(1)\n",
    "        file.close()\n",
    "    pbar.close()\n",
    "        \n",
    "    return sami_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21be9bc6-a39a-47bb-809d-072f634f5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(params = None):\n",
    "    # Define the cutoff frequencies\n",
    "    lowcut = 1/(100/60)  # 100 minutes in units of sample^-1\n",
    "    highcut = 1/(30/60) # 30 minutes in units of sample^-1\n",
    "\n",
    "    # Define the Butterworth filter\n",
    "    nyquist = 0.5 * 5 # 5 minutes is the sampling frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    sos = signal.butter(2, [low, high], btype='bandstop', output='sos')\n",
    "    return sos\n",
    "\n",
    "def remove_background(time_series, sos):\n",
    "\n",
    "\n",
    "    # Apply the filter to the time series\n",
    "    filtered_data = signal.sosfiltfilt(sos, time_series)\n",
    "\n",
    "    return filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5b02b67-e1ff-420d-b68a-4f1896b3acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_to_cart(lats_, lons_, alts_, ntime):\n",
    "    \"\"\"\n",
    "    get cartesian from a grid slice\n",
    "    \"\"\"\n",
    "    \n",
    "    coord_arr = []\n",
    "    \n",
    "    if type(alts_) != list:\n",
    "        if type(alts_) != np.array:\n",
    "            if type(alts_) != np.ndarray:\n",
    "                alts_ = [ alts_ ]\n",
    "\n",
    "\n",
    "    for lat in lats_:\n",
    "        for lon in lons_:\n",
    "            for alt in alts_:\n",
    "                coord_arr.append([(alt + 6371)/6371, lat, lon])\n",
    "                \n",
    "    dtime = times[ntime]\n",
    "\n",
    "    coords = Coords(coord_arr, 'GEO','sph')\n",
    "    coords.ticks = Ticktock([dtime for k in range(len(coord_arr))])\n",
    "\n",
    "    newcoords = coords.convert('GEO','car')\n",
    "    \n",
    "    return newcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d778981-747b-42aa-b279-96df77c0f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_cartesian(grid, ntime):\n",
    "\n",
    "    coords0 = list(zip(grid['malt'].flatten()/ 6371 , grid['mlat'].flatten(), grid['mlon'].flatten()))\n",
    "    dtime = times[ntime]\n",
    "\n",
    "    coords = Coords(coords0, 'CDMAG','sph')\n",
    "    coords.ticks = Ticktock([dtime for k in range(len(coords0))])\n",
    "\n",
    "    newcoords = coords.convert('GEO','car')\n",
    "    \n",
    "    return newcoords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1295e-8e67-4070-a4d3-3a8298ad5c10",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e60f9-b976-4377-b498-7b4a7e2331f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1257dfb0-4f99-4470-8901-68c75a355949",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz, nf, nlt, nt = get_grid_elems_from_parammod(sami_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4fccf47-219d-4f42-be67-694f72026d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "times, hrs, times_list, nts = make_times(dtime_sim_start, nt, plot_start_delta, plot_end_delta)\n",
    "new_nt = np.diff(nts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc52af5f-e6d9-4b68-9b38-9e9204390042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OR.... to run for all times:\n",
    "# times, hrs, times_list = make_times(dtime_sim_start, nt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "890d8402-e9ac-44d4-8ec3-291175481b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 72 256 (428, 524) 96\n"
     ]
    }
   ],
   "source": [
    "print(nlt, nf, nz, nts, new_nt)\n",
    "nt = new_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6940915-bddd-4557-8a27-7f6eccd774a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a88a0c-2df7-482a-98ab-18e7b01a7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_sami_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0e9e1-7b3c-4380-a70b-056feb74ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in grid.keys():\n",
    "    print(g, grid[g].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d333a8a-6fc6-49cc-a060-02b06ae93d73",
   "metadata": {},
   "outputs": [
    {
     "ename": "TqdmKeyError",
     "evalue": "\"Unknown argument(s): {'name': 'reading sami data'}\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTqdmKeyError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sami grid\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sami_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_sami_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# or\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sami_data = read_sami_data(cols, nt)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msami data shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, sami_data[cols[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[61], line 27\u001b[0m, in \u001b[0;36mread_sami_data\u001b[0;34m(cols, nts)\u001b[0m\n\u001b[1;32m     24\u001b[0m     t_end \u001b[38;5;241m=\u001b[39m nt\n\u001b[1;32m     25\u001b[0m     ntimes \u001b[38;5;241m=\u001b[39m nt\n\u001b[0;32m---> 27\u001b[0m pbar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mntimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreading sami data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m     31\u001b[0m     sami_data[f] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nlt,nf,nz,ntimes))\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/tqdm/notebook.py:231\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m colour \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    230\u001b[0m display_here \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgui\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/tqdm/asyncio.py:24\u001b[0m, in \u001b[0;36mtqdm_asyncio.__init__\u001b[0;34m(self, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_asyncio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_awaitable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/tqdm/std.py:1012\u001b[0m, in \u001b[0;36mtqdm.__init__\u001b[0;34m(self, iterable, desc, total, leave, file, ncols, mininterval, maxinterval, miniters, ascii, disable, unit, unit_scale, dynamic_ncols, smoothing, bar_format, initial, position, postfix, unit_divisor, write_bytes, lock_args, nrows, colour, delay, gui, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_free_pos(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m (\n\u001b[1;32m   1013\u001b[0m         TqdmDeprecationWarning(\n\u001b[1;32m   1014\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`nested` is deprecated and automated.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1015\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `position` instead for manual control.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1016\u001b[0m             fp_write\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m, sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite))\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnested\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m         TqdmKeyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown argument(s): \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(kwargs)))\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# Preprocess the arguments\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1022\u001b[0m     (ncols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m nrows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (file \u001b[38;5;129;01min\u001b[39;00m (sys\u001b[38;5;241m.\u001b[39mstderr, sys\u001b[38;5;241m.\u001b[39mstdout))\n\u001b[1;32m   1023\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m dynamic_ncols:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mTqdmKeyError\u001b[0m: \"Unknown argument(s): {'name': 'reading sami data'}\""
     ]
    }
   ],
   "source": [
    "# sami grid\n",
    "sami_data = read_sami_data(cols, nts)\n",
    "# or\n",
    "# sami_data = read_sami_data(cols, nt)\n",
    "\n",
    "print('sami data shape: ', sami_data[cols[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceff5a1-38f1-4128-995d-cabe803230da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if to_filter:\n",
    "#     print('Calculating fits. This will take a moment...')\n",
    "#     fits_sami = make_fits(sami_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a7d6d-fc88-4379-a313-27f7fdca042f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaf1bd-50e9-44f7-912e-6d05ba708d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlons = np.unique(grid['mlon'].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641f91c-30b1-4eaa-a82e-9e2dce78bd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe785fc-5e64-4c9b-ad11-a9b2884ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('example data shape: ', sami_data['edens'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65623aa0-9ac2-4f8a-848d-a3a48f239210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e48f40-3bdb-49d3-9ae8-1e5085ce0c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc064afe-7b09-4257-9af8-d35abf4a3e2f",
   "metadata": {},
   "source": [
    "## I think this is the best way to do it... Need to make sure we can resolve LSTIDS though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f55e7-c9aa-4322-be34-fc8c5a21559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_alts = (grid['alt'].flatten() < (max(out_alts) + 300)) & (grid['alt'].flatten() > (min(out_alts)-75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06364abc-55c3-4825-970a-d7f300d2338d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pbar = tqdm(total = len(times)*len(cols), desc = 'making fits')\n",
    "\n",
    "# this will be very messy. clean up after the processing is done.\n",
    "\n",
    "def interp_grid(col):\n",
    "    preds = {}\n",
    "    preds[col] = np.zeros([len(times),len(out_lats), len(out_lons),  len(out_alts)])\n",
    "    \n",
    "    for ntime, dt in enumerate(times):\n",
    "\n",
    "        # print('cart grid')\n",
    "        grid_cart = grid_to_cartesian(grid, ntime)\n",
    "\n",
    "        xs = grid_cart.data[:,0][norm_alts]\n",
    "        ys = grid_cart.data[:,1][norm_alts]\n",
    "        zs = grid_cart.data[:,2][norm_alts]\n",
    "\n",
    "        # print('zipping')\n",
    "\n",
    "        loc_grid = list(zip(xs, ys, zs))\n",
    "\n",
    "        # print('making output grid')\n",
    "\n",
    "        out_grid = geo_to_cart(out_lats, out_lons, out_alts, ntime)\n",
    "\n",
    "        out_xs = out_grid.data[:,0]\n",
    "        out_ys = out_grid.data[:,1]\n",
    "        out_zs = out_grid.data[:,2]\n",
    "\n",
    "        datas = sami_data[col][:,:,:,ntime].flatten()[norm_alts]\n",
    "\n",
    "        # print('building interpolator')\n",
    "\n",
    "        interp = LinearNDInterpolator(loc_grid , datas, rescale = True)\n",
    "        # print('interpolating')\n",
    "        pred = interp(list(zip(out_xs, out_ys, out_zs)))\n",
    "\n",
    "        # break\n",
    "\n",
    "        preds[ntime] = pred.reshape([len(out_lats), len(out_lons), len(out_alts)])\n",
    "\n",
    "        pbar.update(1)\n",
    "    return preds\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c806b-a11e-4363-b3a5-c4f80f37580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thread the above function, if thread option is set.\n",
    "\n",
    "if thread:\n",
    "    with Pool(len(cols)) as pool:\n",
    "\n",
    "        pred_inter = pool.map(interp_grid, cols)\n",
    "        \n",
    "    ## Clean up predictions... Returns a list of dicts when threaded.\n",
    "\n",
    "    \n",
    "else:\n",
    "    pred_inter = []\n",
    "    for col in cols:\n",
    "        pred_inter.append(interp_grid[col])\n",
    "        \n",
    "preds_cleaned = {}\n",
    "for p in pred_inter:\n",
    "    for k in p.keys():\n",
    "        preds_cleaned[k] = p[k]\n",
    "preds = preds_cleaned\n",
    "del preds_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109566c4-67df-4114-b85f-3bb12cd0e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if debug:\n",
    "    a = 5\n",
    "    \n",
    "    ## COmpare maps\n",
    "    plt.imshow(preds[cols[0]][0,:,:,a], origin = 'lower', extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    alt_mask_plot = (np.abs(grid['alt'].flatten() - out_alts[a]) < 10)\n",
    "    plt.scatter(grid['glon'].flatten()[alt_mask_plot], grid['glat'].flatten()[alt_mask_plot], c = sami_data['edens'][:,:,:,ntime].flatten()[alt_mask_plot])\n",
    "    plt.ylim(min(out_lats), max(out_lats))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2a5f8-0480-4ecc-8f96-9e5e8c693685",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_filter:\n",
    "    sos = make_filter()\n",
    "    filtered = {}\n",
    "    for col in cols:\n",
    "        filtered[col] = signal.sosfiltfilt(sos, preds[col], axis = 0)\n",
    "        \n",
    "    if debug:\n",
    "        plt.imshow(preds[cols[0]][0,:,:,a], origin = 'lower', extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        plt.imshow(100*(preds[cols[0]][25,:,:,a] - filtered[cols[0]][25,:,:,a])/preds[cols[0]][1,:,:,a], origin = 'lower', \n",
    "                   extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto', vmin = -5, vmax = 5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        for l in range(0, len(out_lons),4):\n",
    "            plt.figure(figsize = (8,4))\n",
    "            plt.imshow((100*(preds[cols[0]][:,:,l,a] - filtere[cols[0]]d[:,:,l,a])/preds[cols[0]][:,:,l,a]).T, \n",
    "                       extent = [min(hrs), max(hrs), min(out_lats), max(out_lats)], aspect = 'auto', vmin = -4, vmax = 4)\n",
    "            plt.colorbar(label = 'edends % over background at ' + str(out_alts[a]) + ' km')\n",
    "            plt.title('glon = ' + str(out_lons[l].round(2)))\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13271b96-b3de-46b0-961c-b811795be746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d2c72b2-0623-4081-8028-a605e9495e4b",
   "metadata": {},
   "source": [
    "## Save everything to files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66981c60-cf1c-4962-ac41-78b5dd759619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe4789-4bf0-4f51-b802-a8800a3524ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(times).to_file(data_out_path + 'times')\n",
    "out_lats.to_file(data_out_path + 'out-lats')\n",
    "out_lons.to_file(data_out_path + 'out-lons')\n",
    "out_alts.to_file(data_out_path + 'out-alts')\n",
    "\n",
    "np.array(preds[cols[0]].shape).to_tile(sami_data_path + 'example_shape')\n",
    "\n",
    "for col in cols:\n",
    "\n",
    "    preds[col].tofile(data_out_path + 'preds-' + col)\n",
    "    \n",
    "    if to_filter:\n",
    "        filtered[col].to_file(data_out_path + 'bp_filtered-' + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08407a-1ae3-46b4-a364-c42ea4fe4dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76381c6b-d2dd-4ec8-9063-0a39181e3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57034448-9de4-4d61-b27d-a0296421eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list is  1 2 3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b57f72-c52f-4611-8a38-711ea8a1946e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
