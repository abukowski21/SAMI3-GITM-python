{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691b33d-3de4-4897-ab9d-535ad34609b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01555b18-1a55-469f-ac5c-6ea4c45a5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aacgmv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import math, os, shutil\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import datetime\n",
    "from scipy import signal\n",
    "\n",
    "from spacepy.coordinates import Coords\n",
    "from spacepy.time import Ticktock\n",
    "import fnmatch\n",
    "import sys\n",
    "from scipy.interpolate import LinearNDInterpolator, interp1d, griddata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ff191-7c04-428d-8a81-c17ab9fdfcc8",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d83e43-9a75-44f3-ad71-c83a71360efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime_storm_start = datetime.datetime(2011,5,21,13,40) \n",
    "\n",
    "dtime_sim_start = datetime.datetime(2011,5,20)\n",
    "\n",
    "t_step_minutes = 5 # minutes\n",
    "\n",
    "\n",
    "plot_start_delta  = 3  # hours before storm onset to start making plots. set to -1 to run the whole time\n",
    "plot_end_delta    = 9  # hours after storm onset to end plots. Set to -1 to run for the whole time\n",
    "\n",
    "sami_data_path = \"/home/axb170054/scratch/GITM-testing/test_folders/step_function_driving/SAMI3-stretch/\"\n",
    "\n",
    "\n",
    "global_lat_lim = 65 # will limit SAMI output data to this GEO latitude\n",
    "\n",
    "\n",
    "sample_rate_min = 5 # SHOULD be the same as t_step_minutes above. If not, something will be wrong. Won't throw errors. Gotta pay attention.\n",
    "low_cut = 100 # min, lowest freq wave the filter will allow thru\n",
    "high_cut = 40 # min, highest freq the filter will allow thru\n",
    "\n",
    "\n",
    " #Do we want to run the filtering? if not, this will need to be done later.\n",
    "to_filter = False # This is not implemented yet!!! Would be a good project for someone.\n",
    "debug = False # make plots at the end? I would leave this as False. At the bottom there are some simple plotting routines. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b35c0a-5b44-4bff-8bc2-c20ad6eb1f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6040fcc7-0777-4e0a-8100-48ef32295916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']\n",
    "\n",
    "# above is all cols (that I care about), below is just edens. If we want to output more columns, add them to data_files below too.\n",
    "\n",
    "# cols = ['edens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804d66f-a768-49f3-a67f-82ad7d977388",
   "metadata": {},
   "source": [
    "Available columns (for now) are:\n",
    "\n",
    "['edens', 'hplusdens', 'oplusdens', 'noplusdens', 'o2plusdens', 'heplusdens', 'n2plusdens', 'nplusdens', 'hdens', 'odens', 'nodens', 'o2dens', 'hedens', 'n2dens', 'ndens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4588e6d7-6fc5-40c3-b029-26535b368b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data mapped to a grid will go here\n",
    "data_out_path = '/home/axb170054/scratch/pickles/SimStormPaper/simstorm_sami_files/'\n",
    "save_raw = False # output txt files for raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a65552d-890d-42bb-9a1c-e1d52836d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Options for multithreading. \n",
    "thread = True \n",
    "num_workers = len(cols) # adjust this to fit your system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40463bd2-f31b-4974-b9f5-2b26fd25595d",
   "metadata": {},
   "source": [
    "### Speficy the output grid\n",
    "\n",
    "Lats & lons are calculated, altitudes must be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8962264b-72ce-43d4-b77f-47e437bb01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_grid_lats = 65 #number of lats\n",
    "out_grid_lons = 75 #number of lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a1d00a-952c-4604-a92d-4208cb65949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_lats = np.linspace(-global_lat_lim,global_lat_lim, out_grid_lats)\n",
    "out_lons = np.linspace(0,360, out_grid_lons +1)[1:] # we don't need both 0 & 360. the 1's deal with that.\n",
    "out_alts = np.array([250,300,350,400,450,500,550,600,700,800,840,880,900,1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6ebc12-1a21-4ca8-8225-8fc353b2ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-65.     , -62.96875, -60.9375 , -58.90625, -56.875  , -54.84375,\n",
       "        -52.8125 , -50.78125, -48.75   , -46.71875, -44.6875 , -42.65625,\n",
       "        -40.625  , -38.59375, -36.5625 , -34.53125, -32.5    , -30.46875,\n",
       "        -28.4375 , -26.40625, -24.375  , -22.34375, -20.3125 , -18.28125,\n",
       "        -16.25   , -14.21875, -12.1875 , -10.15625,  -8.125  ,  -6.09375,\n",
       "         -4.0625 ,  -2.03125,   0.     ,   2.03125,   4.0625 ,   6.09375,\n",
       "          8.125  ,  10.15625,  12.1875 ,  14.21875,  16.25   ,  18.28125,\n",
       "         20.3125 ,  22.34375,  24.375  ,  26.40625,  28.4375 ,  30.46875,\n",
       "         32.5    ,  34.53125,  36.5625 ,  38.59375,  40.625  ,  42.65625,\n",
       "         44.6875 ,  46.71875,  48.75   ,  50.78125,  52.8125 ,  54.84375,\n",
       "         56.875  ,  58.90625,  60.9375 ,  62.96875,  65.     ]),\n",
       " array([  4.8,   9.6,  14.4,  19.2,  24. ,  28.8,  33.6,  38.4,  43.2,\n",
       "         48. ,  52.8,  57.6,  62.4,  67.2,  72. ,  76.8,  81.6,  86.4,\n",
       "         91.2,  96. , 100.8, 105.6, 110.4, 115.2, 120. , 124.8, 129.6,\n",
       "        134.4, 139.2, 144. , 148.8, 153.6, 158.4, 163.2, 168. , 172.8,\n",
       "        177.6, 182.4, 187.2, 192. , 196.8, 201.6, 206.4, 211.2, 216. ,\n",
       "        220.8, 225.6, 230.4, 235.2, 240. , 244.8, 249.6, 254.4, 259.2,\n",
       "        264. , 268.8, 273.6, 278.4, 283.2, 288. , 292.8, 297.6, 302.4,\n",
       "        307.2, 312. , 316.8, 321.6, 326.4, 331.2, 336. , 340.8, 345.6,\n",
       "        350.4, 355.2, 360. ]),\n",
       " array([ 250,  300,  350,  400,  450,  500,  550,  600,  700,  800,  840,\n",
       "         880,  900, 1000]),\n",
       " 65,\n",
       " 75,\n",
       " 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lats, out_lons, out_alts, len(out_lats), len(out_lons), len(out_alts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31be945-574a-4a9f-8c4d-463ec5dfaab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bdea72-c7ec-4691-871c-5a97e4990c6c",
   "metadata": {},
   "source": [
    "## Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aef03d2-d9ff-4b97-856a-33129c0a97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_grid_files = {'glat':'glatu.dat','glon':'glonu.dat','alt':'zaltu.dat', \n",
    "                  'mlat':'blatu.dat','mlon':'blonu.dat','malt':'baltu.dat'}\n",
    "\n",
    "\n",
    "data_files = {'edens':'deneu.dat', 'hplusdens':'deni1u.dat','oplusdens':'deni2u.dat',\n",
    "              'noplusdens':'deni3u.dat', 'o2plusdens':'deni4u.dat',\n",
    "              'heplusdens':'deni5u.dat', 'n2plusdens':'deni6u.dat', \n",
    "              'nplusdens':'deni7u.dat','hdens':'denn1u.dat','odens':'denn2u.dat', \n",
    "              'nodens':'denn3u.dat', 'o2dens':'denn4u.dat', 'hedens':'denn5u.dat', \n",
    "              'n2dens':'denn6u.dat', 'ndens':'denn7u.dat'}\n",
    "\n",
    "time_file = 'time.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fe50e-3a3d-465b-9343-18e00c00150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5934c36f-340d-4676-860e-39b4a4ab8db0",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96832d5-41e5-4bba-80b7-ea1b9d117c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grid_elems_from_parammod(data_dir):\n",
    "    \"\"\"\n",
    "    Will look for: words = ['nz0','nf','nl'] in SAMI files. You can either run this or set the elements yourself.\n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    sami path\n",
    "    \n",
    "    outputs:\n",
    "    -------\n",
    "    nz,nf,nlt,nt :\n",
    "    - nz  = num points along field line\n",
    "    - nf  = num field lines along each mag lon\n",
    "    - nlt = num mag lons\n",
    "    - nt  = num times\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Make sure that we only grab the first instance of each var in the file. \n",
    "        # SOmetimes they repeat and we don't want them\n",
    "    returns = [False, False, [False, False], False]\n",
    "    \n",
    "    with open(data_dir  + 'parameter_mod.f90', 'r') as fp:\n",
    "    # read all lines in a list\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            # check if string present on a current line\n",
    "            \n",
    "            if not returns[0]:\n",
    "                if line.find('nz0') != -1:\n",
    "                    nz0 = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nz0.append(l)\n",
    "                    if len(nz0[1:4]) == 3:\n",
    "                        nz = int(''.join(nz0[1:4]))\n",
    "                        returns[0] = True\n",
    "            \n",
    "            if not returns[1]:\n",
    "                if line.find('nf') != -1:\n",
    "                    nf = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nf.append(l)\n",
    "                    nf = int(''.join(nf))\n",
    "                    returns[1] = True\n",
    "                    \n",
    "            if not returns[2][0]:\n",
    "                if line.find('nl ') != -1:\n",
    "                    nl = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            nl.append(l)\n",
    "                    nl = int(''.join(nl))\n",
    "                    returns[2][0] = True\n",
    "                    \n",
    "            if not returns[2][1]:\n",
    "                if line.find('numwork ') != -1:\n",
    "                    numwork = []\n",
    "                    for l in line:\n",
    "                        if l.isdigit():\n",
    "                            numwork.append(l)\n",
    "                    numwork = int(''.join(numwork))\n",
    "                    returns[2][1] = True\n",
    "                    \n",
    "    #time\n",
    "    with open(data_dir  + 'time.dat', 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        nt = len(lines) - 1\n",
    "            \n",
    "    return nz, nf, numwork*(nl - 2), nt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c89024-7bd4-4e03-971b-04ed0daad573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_times(t0, nt, plot_start_delta = None, plot_end_delta = None):\n",
    "    times = []\n",
    "    hrs_since_storm_start = []\n",
    "    \n",
    "    for t in range(nt):\n",
    "        time_here = pd.Timestamp(dtime_sim_start) + t * pd.Timedelta(5, 'minutes')\n",
    "        times.append(time_here.to_pydatetime())\n",
    "        hrs = (time_here - dtime_storm_start)/pd.Timedelta(1, 'hour')\n",
    "        hrs_since_storm_start.append(hrs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    times_df = pd.read_fwf(os.path.join(sami_data_path, 'time.dat'), \n",
    "                            names = ['istep', 'hour', 'minute', 'second', 'hrdelta'], infer_nrows=115)\n",
    "    times_df.pop('istep');\n",
    "\n",
    "    times_list = []\n",
    "    for hr in times_df['hrdelta']:\n",
    "        times_list.append(dtime_sim_start + datetime.timedelta(hours = hr))    \n",
    "    \n",
    "    truths = np.array([pd.Timestamp(times_list[t]).round('T') == times[t] for t in range(len(times))])\n",
    "    if truths.sum() != len(truths):\n",
    "        raise ValueError('The times are wrong! Somehow this needs to be fixed. probably outputting fake files again. Take a look and debug before proceeding.')\n",
    "        \n",
    "    #maybe chop the time lists, depending on if the plot start/end are given.\n",
    "    # adjusted to allow for -1 in plot start/end deltas (plot all times)\n",
    "        \n",
    "    if plot_start_delta and plot_end_delta:\n",
    "        if plot_start_delta != -1:\n",
    "            start_idx = np.argmin(np.abs(np.array(times) \n",
    "                                     - (dtime_storm_start - pd.Timedelta(plot_start_delta, 'hour'))))\n",
    "        else:\n",
    "            start_idx = 0\n",
    "            \n",
    "        if plot_end_delta != -1:\n",
    "            end_idx = np.argmin(np.abs(np.array(times) \n",
    "                                     - (dtime_storm_start + pd.Timedelta(plot_end_delta, 'hour'))))\n",
    "        elif plot_end_delta == -1:\n",
    "            end_idx = len(times)\n",
    "        else:\n",
    "            end_idx = len(times)\n",
    "        \n",
    "        times = times[start_idx:end_idx]\n",
    "        hrs_since_storm_start = hrs_since_storm_start[start_idx:end_idx]\n",
    "        times_list = times_list[start_idx:end_idx]\n",
    "        \n",
    "        return times, hrs_since_storm_start, times_list, (start_idx, end_idx)\n",
    "        \n",
    "    elif plot_start_delta != plot_end_delta:\n",
    "        raise ValueError('You cannot specify one and not the other!')\n",
    "    \n",
    "    return times, hrs_since_storm_start, times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd9f2ee0-e5db-4ed4-9a25-2b68ad88cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sami_grid(sami_data_path = sami_data_path, geo_grid_files = geo_grid_files):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    dictionary\n",
    "        - grid['key'][nlt , nf, nz]\n",
    "        \n",
    "        key = grid file: glat, glon, alt, etc.\n",
    "        nlt, nf, nz; see get_grid_elems_from_parammod\n",
    "        \n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    grid = {}\n",
    "\n",
    "    for f in geo_grid_files:\n",
    "        file = open(os.path.join(sami_data_path, geo_grid_files[f]), 'rb')\n",
    "        raw = np.fromfile(file, dtype='float32')[1:-1].copy()\n",
    "        file.close()\n",
    "\n",
    "        grid[f] = raw.reshape(nlt,nf,nz).copy()\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b81a498-d13a-4223-8d88-c30f078322d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sami_data(cols, nts):\n",
    "    \"\"\"\n",
    "    Read in sami data for the specified columns and return sama data dict\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    cols: list-like\n",
    "        - Columns you want data for. Does not have to be everything\n",
    "    \n",
    "    nts: int OR tuple/list\n",
    "        - either nt (number of times) if you want all sami data from simulation or:\n",
    "        - nts (start_time, end_time) if you want plots from a select time period.\n",
    "        \n",
    "        \n",
    "    return:\n",
    "    dictionary\n",
    "        - sami_data['key'][nlt , nf, nz, ntime]\n",
    "        \n",
    "        key = column: edens, hdens, etc.\n",
    "        nlt, nf, nz; see get_grid_elems_from_parammod\n",
    "        ntime = time index.\n",
    "    \"\"\"\n",
    "    sami_data = {}\n",
    "    \n",
    "    #handle cut time list and full time list\n",
    "    if type(nts) != int:\n",
    "        t_start = nts[0]\n",
    "        t_end   = nts[1]\n",
    "        ntimes = t_end - t_start\n",
    "    else:\n",
    "        t_start = 0\n",
    "        t_end = nt\n",
    "        ntimes = nt\n",
    "        \n",
    "    pbar = tqdm(total = len(cols) * ntimes, desc = 'reading sami data')\n",
    "\n",
    "    for f in cols:\n",
    "\n",
    "        sami_data[f] = np.zeros((nlt,nf,nz,ntimes))\n",
    "\n",
    "        file = open(os.path.join(sami_data_path, data_files[f]), 'rb')\n",
    "        for t in range(t_end):\n",
    "            raw = np.fromfile(file, dtype='float32', count = (nz*nf*nlt)+2)[1:-1]\n",
    "            if t >= t_start:\n",
    "                sami_data[f][:,:,:,t-t_start] = raw.reshape(nlt,nf,nz).copy()\n",
    "                pbar.update(1)\n",
    "        file.close()\n",
    "    pbar.close()\n",
    "        \n",
    "    return sami_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21be9bc6-a39a-47bb-809d-072f634f5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bandpass filtering\n",
    "\n",
    "\n",
    "def make_filter(params = None):\n",
    "    # Define the cutoff frequencies\n",
    "    lowcut = 1/(100/60)  # 100 minutes in units of sample^-1\n",
    "    highcut = 1/(30/60) # 30 minutes in units of sample^-1\n",
    "\n",
    "    # Define the Butterworth filter\n",
    "    nyquist = 0.5 * 5 # 5 minutes is the sampling frequency\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    sos = signal.butter(2, [low, high], btype='bandstop', output='sos')\n",
    "    return sos\n",
    "\n",
    "def remove_background(time_series, sos):\n",
    "\n",
    "\n",
    "    # Apply the filter to the time series\n",
    "    filtered_data = signal.sosfiltfilt(sos, time_series)\n",
    "\n",
    "    return filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b02b67-e1ff-420d-b68a-4f1896b3acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_to_cart(lats_, lons_, alts_, ntime):\n",
    "    \"\"\"\n",
    "    get cartesian from a grid slice\n",
    "    \"\"\"\n",
    "    \n",
    "    coord_arr = []\n",
    "    \n",
    "    if type(alts_) != list:\n",
    "        if type(alts_) != np.array:\n",
    "            if type(alts_) != np.ndarray:\n",
    "                alts_ = [ alts_ ]\n",
    "\n",
    "\n",
    "    for lat in lats_:\n",
    "        for lon in lons_:\n",
    "            for alt in alts_:\n",
    "                coord_arr.append([(alt + 6371)/6371, lat, lon])\n",
    "                \n",
    "    dtime = times[ntime]\n",
    "\n",
    "    coords = Coords(coord_arr, 'GEO','sph')\n",
    "    coords.ticks = Ticktock([dtime for k in range(len(coord_arr))])\n",
    "\n",
    "    newcoords = coords.convert('GEO','car')\n",
    "    \n",
    "    return newcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d778981-747b-42aa-b279-96df77c0f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_cartesian(grid, ntime):\n",
    "    \"\"\" get cartesian coords of the output grid\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    coords0 = list(zip(grid['malt'].flatten()/ 6371 , grid['mlat'].flatten(), grid['mlon'].flatten()))\n",
    "    dtime = times[ntime]\n",
    "\n",
    "    coords = Coords(coords0, 'CDMAG','sph')\n",
    "    coords.ticks = Ticktock([dtime for k in range(len(coords0))])\n",
    "\n",
    "    newcoords = coords.convert('GEO','car')\n",
    "    \n",
    "    return newcoords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1295e-8e67-4070-a4d3-3a8298ad5c10",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e60f9-b976-4377-b498-7b4a7e2331f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1257dfb0-4f99-4470-8901-68c75a355949",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz, nf, nlt, nt = get_grid_elems_from_parammod(sami_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4fccf47-219d-4f42-be67-694f72026d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "times, hrs, times_list, nts = make_times(dtime_sim_start, nt, plot_start_delta, plot_end_delta)\n",
    "new_nt = np.diff(nts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc52af5f-e6d9-4b68-9b38-9e9204390042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OR.... to run for all times:\n",
    "# times, hrs, times_list = make_times(dtime_sim_start, nt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "890d8402-e9ac-44d4-8ec3-291175481b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 72 256 (416, 560) 144\n"
     ]
    }
   ],
   "source": [
    "print(nlt, nf, nz, nts, new_nt)\n",
    "nt = new_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6940915-bddd-4557-8a27-7f6eccd774a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32a88a0c-2df7-482a-98ab-18e7b01a7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = get_sami_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe0e9e1-7b3c-4380-a70b-056feb74ff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glat (80, 72, 256)\n",
      "glon (80, 72, 256)\n",
      "alt (80, 72, 256)\n",
      "mlat (80, 72, 256)\n",
      "mlon (80, 72, 256)\n",
      "malt (80, 72, 256)\n"
     ]
    }
   ],
   "source": [
    "for g in grid.keys():\n",
    "    print(g, grid[g].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d333a8a-6fc6-49cc-a060-02b06ae93d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2fad408c26458d811aca2afaa41aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading sami data:   0%|          | 0/2160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sami data shape:  (80, 72, 256, 144)\n"
     ]
    }
   ],
   "source": [
    "# sami grid\n",
    "sami_data = read_sami_data(cols, nts)\n",
    "# or\n",
    "# sami_data = read_sami_data(cols, nt)\n",
    "\n",
    "print('sami data shape: ', sami_data[cols[0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ceff5a1-38f1-4128-995d-cabe803230da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_filter:\n",
    "    print('Calculating fits. This will take a moment...')\n",
    "    fits_sami = make_fits(sami_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a7d6d-fc88-4379-a313-27f7fdca042f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641f91c-30b1-4eaa-a82e-9e2dce78bd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe785fc-5e64-4c9b-ad11-a9b2884ceb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example data shape:  (80, 72, 256, 96)\n"
     ]
    }
   ],
   "source": [
    "print('example data shape: ', sami_data['edens'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65623aa0-9ac2-4f8a-848d-a3a48f239210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e48f40-3bdb-49d3-9ae8-1e5085ce0c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc064afe-7b09-4257-9af8-d35abf4a3e2f",
   "metadata": {},
   "source": [
    "## Do the interpolation.\n",
    "\n",
    "\n",
    "1. Limit the iput data to a reasonable alt range.\n",
    "2. map inputs & outputs to cartesian (at each datetime)\n",
    "3. do interpolations\n",
    "4. output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b99f55e7-c9aa-4322-be34-fc8c5a21559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_alts = (grid['alt'].flatten() < (max(out_alts) + 300)) & (grid['alt'].flatten() > (min(out_alts)-75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d029b435-abcc-4a48-b767-e256cff27fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 250,  300,  350,  400,  450,  500,  550,  600,  700,  800,  840,\n",
       "         880,  900, 1000]),\n",
       " array([  4.8,   9.6,  14.4,  19.2,  24. ,  28.8,  33.6,  38.4,  43.2,\n",
       "         48. ,  52.8,  57.6,  62.4,  67.2,  72. ,  76.8,  81.6,  86.4,\n",
       "         91.2,  96. , 100.8, 105.6, 110.4, 115.2, 120. , 124.8, 129.6,\n",
       "        134.4, 139.2, 144. , 148.8, 153.6, 158.4, 163.2, 168. , 172.8,\n",
       "        177.6, 182.4, 187.2, 192. , 196.8, 201.6, 206.4, 211.2, 216. ,\n",
       "        220.8, 225.6, 230.4, 235.2, 240. , 244.8, 249.6, 254.4, 259.2,\n",
       "        264. , 268.8, 273.6, 278.4, 283.2, 288. , 292.8, 297.6, 302.4,\n",
       "        307.2, 312. , 316.8, 321.6, 326.4, 331.2, 336. , 340.8, 345.6,\n",
       "        350.4, 355.2, 360. ]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_alts, out_lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06364abc-55c3-4825-970a-d7f300d2338d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f79e36dec254f4096080f1af82faaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "making fits:   0%|          | 0/1440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pbar = tqdm(total = len(times)*len(cols), desc = 'making fits')\n",
    "\n",
    "# this will be very messy. clean up after the processing is done.\n",
    "\n",
    "def interp_grid(col):\n",
    "    preds = {}\n",
    "    preds[col] = np.zeros([len(times),len(out_lats), len(out_lons),  len(out_alts)])\n",
    "    \n",
    "    for ntime, dt in enumerate(times):\n",
    "\n",
    "        grid_cart = grid_to_cartesian(grid, ntime)\n",
    "\n",
    "        xs = grid_cart.data[:,0][norm_alts]\n",
    "        ys = grid_cart.data[:,1][norm_alts]\n",
    "        zs = grid_cart.data[:,2][norm_alts]\n",
    "\n",
    "\n",
    "        loc_grid = list(zip(xs, ys, zs))\n",
    "\n",
    "\n",
    "        out_grid = geo_to_cart(out_lats, out_lons, out_alts, ntime)\n",
    "\n",
    "        out_xs = out_grid.data[:,0]\n",
    "        out_ys = out_grid.data[:,1]\n",
    "        out_zs = out_grid.data[:,2]\n",
    "\n",
    "        datas = sami_data[col][:,:,:,ntime].flatten()[norm_alts]\n",
    "\n",
    "\n",
    "        interp = LinearNDInterpolator(loc_grid , datas, rescale = True)\n",
    "        pred = interp(list(zip(out_xs, out_ys, out_zs)))\n",
    "\n",
    "        preds[col][ntime] = pred.reshape([len(out_lats), len(out_lons), len(out_alts)])\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    return preds\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b52c806b-a11e-4363-b3a5-c4f80f37580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n",
      "/home/axb170054/.conda/envs/py38/lib/python3.8/site-packages/spacepy/coordinates.py:248: DeprecationWarning: No coordinate backend specified; using SpacePy. This default changed from IRBEM in version 0.4.0\n",
      "  warnings.warn('No coordinate backend specified; using SpacePy.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14676500489.940033 hedens\n",
      "18334775737.929016 n2dens\n",
      "15092640235.64255 hdens\n",
      "12645056.441270534 nplusdens\n",
      "49535726.97728915 hplusdens\n",
      "1427979.812719341 heplusdens\n",
      "6672758601.606803 ndens\n",
      "274353.2180117546 n2plusdens\n",
      "376333801739.8815 odens\n",
      "1621254917.6399298 oplusdens\n",
      "14678513.921858165 nodens\n",
      "337619570.9452592 o2dens\n",
      "1685539895.07889 edens\n",
      "302855.96013359167 noplusdens\n",
      "99007.41826828575 o2plusdens\n"
     ]
    }
   ],
   "source": [
    "#Thread the above function, if thread option is set.\n",
    "\n",
    "if thread:\n",
    "    with Pool(len(cols)) as pool:\n",
    "\n",
    "        pred_inter = pool.map(interp_grid, cols)\n",
    "        \n",
    "    ## Clean up predictions... Returns a list of dicts when threaded.\n",
    "\n",
    "    \n",
    "else:\n",
    "    pred_inter = []\n",
    "    for col in cols:\n",
    "        pred_inter.append(interp_grid[col])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06daf020-6cd5-4c96-8525-7ad41fa136e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the output pred arrays. Things got weird if you had threading on.\n",
    "\n",
    "preds_cleaned = {}\n",
    "for p in pred_inter:\n",
    "    for k in p.keys():\n",
    "        preds_cleaned[k] = p[k]\n",
    "preds = preds_cleaned\n",
    "del preds_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f366b7-dce8-4ec8-8227-1aa298173eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109566c4-67df-4114-b85f-3bb12cd0e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if debug:\n",
    "    a = 5\n",
    "    \n",
    "    ## COmpare maps\n",
    "    plt.imshow(preds[cols[0]][0,:,:,a], origin = 'lower', extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    alt_mask_plot = (np.abs(grid['alt'].flatten() - out_alts[a]) < 10)\n",
    "    plt.scatter(grid['glon'].flatten()[alt_mask_plot], grid['glat'].flatten()[alt_mask_plot], c = sami_data['edens'][:,:,:,ntime].flatten()[alt_mask_plot])\n",
    "    plt.ylim(min(out_lats), max(out_lats))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2a5f8-0480-4ecc-8f96-9e5e8c693685",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_filter and debug:\n",
    "    sos = make_filter()\n",
    "    filtered = {}\n",
    "    for col in cols:\n",
    "        filtered[col] = signal.sosfiltfilt(sos, preds[col], axis = 0)\n",
    "        \n",
    "    if debug:\n",
    "        plt.imshow(preds[cols[0]][0,:,:,a], origin = 'lower', extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        plt.imshow(100*(preds[cols[0]][25,:,:,a] - filtered[cols[0]][25,:,:,a])/preds[cols[0]][1,:,:,a], origin = 'lower', \n",
    "                   extent = [min(out_lons), max(out_lons), min(out_lats), max(out_lats)], aspect = 'auto', vmin = -5, vmax = 5)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        for l in range(0, len(out_lons),4):\n",
    "            plt.figure(figsize = (8,4))\n",
    "            plt.imshow((100*(preds[cols[0]][:,:,l,a] - filtere[cols[0]]d[:,:,l,a])/preds[cols[0]][:,:,l,a]).T, \n",
    "                       extent = [min(hrs), max(hrs), min(out_lats), max(out_lats)], aspect = 'auto', vmin = -4, vmax = 4)\n",
    "            plt.colorbar(label = 'edends % over background at ' + str(out_alts[a]) + ' km')\n",
    "            plt.title('glon = ' + str(out_lons[l].round(2)))\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13271b96-b3de-46b0-961c-b811795be746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d2c72b2-0623-4081-8028-a605e9495e4b",
   "metadata": {},
   "source": [
    "## Save everything to files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66981c60-cf1c-4962-ac41-78b5dd759619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9898798-1075-4f72-b0fc-33a4c37544f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 72, 256, 96)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sami_data['edens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aefe4789-4bf0-4f51-b802-a8800a3524ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing files...\n",
      "written! Exiting. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('writing files...')\n",
    "\n",
    "np.array(times).tofile(data_out_path + 'times', format = '%s', sep = ',')\n",
    "out_lats.tofile(data_out_path + 'out-lats', sep = ',')\n",
    "out_lons.tofile(data_out_path + 'out-lons', sep = ',')\n",
    "out_alts.tofile(data_out_path + 'out-alts', sep = ',')\n",
    "\n",
    "np.array(preds[cols[0]].shape).tofile(data_out_path + 'out-shape', sep = ',')\n",
    "\n",
    "for col in cols:\n",
    "\n",
    "    preds[col].tofile(data_out_path + 'preds-' + col, sep = ',')\n",
    "    \n",
    "    if to_filter:\n",
    "        filtered[col].file(data_out_path + 'bp_filtered-' + col, sep = ',')\n",
    "\n",
    "if save_raw:\n",
    "    for col in cols:\n",
    "\n",
    "        sami_data[col].tofile(data_out_path + 'raw-' + col, sep = ',')\n",
    "\n",
    "\n",
    "np.array(sami_data[cols[0]].shape).tofile(data_out_path + 'raw-shape', sep = ',')\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "print('written! Exiting. ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
